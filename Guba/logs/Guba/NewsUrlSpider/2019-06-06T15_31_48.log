2019-06-06 15:31:53 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: Guba)
2019-06-06 15:31:53 [scrapy.utils.log] INFO: Versions: lxml 4.3.2.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.7.3 (default, Mar 27 2019, 16:54:48) - [Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1b  26 Feb 2019), cryptography 2.6.1, Platform Darwin-18.6.0-x86_64-i386-64bit
2019-06-06 15:31:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'Guba', 'CONCURRENT_REQUESTS': 8, 'DOWNLOAD_DELAY': 1, 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter', 'LOG_FILE': 'logs/Guba/NewsUrlSpider/2019-06-06T15_31_48.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'Guba.spiders', 'ROBOTSTXT_OBEY': True, 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler', 'SPIDER_MODULES': ['Guba.spiders']}
2019-06-06 15:31:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2019-06-06 15:31:53 [NewsUrlSpider] INFO: Reading start URLs from redis key 'Guba:start_urls' (batch size: 8, encoding: utf-8
2019-06-06 15:31:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'Guba.middlewares.RandomUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-06-06 15:31:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-06-06 15:31:53 [scrapy.middleware] INFO: Enabled item pipelines:
['Guba.pipelines.GubaPipeline']
2019-06-06 15:31:53 [scrapy.core.engine] INFO: Spider opened
2019-06-06 15:31:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:32:53 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 46 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:33:53 [scrapy.extensions.logstats] INFO: Crawled 96 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:34:53 [scrapy.extensions.logstats] INFO: Crawled 142 pages (at 46 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:35:53 [scrapy.extensions.logstats] INFO: Crawled 191 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:36:53 [scrapy.extensions.logstats] INFO: Crawled 235 pages (at 44 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:37:53 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:38:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,600349,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 15:38:53 [scrapy.extensions.logstats] INFO: Crawled 335 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:39:53 [scrapy.extensions.logstats] INFO: Crawled 383 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:40:53 [scrapy.extensions.logstats] INFO: Crawled 431 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:41:53 [scrapy.extensions.logstats] INFO: Crawled 478 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:42:53 [scrapy.extensions.logstats] INFO: Crawled 527 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:43:53 [scrapy.extensions.logstats] INFO: Crawled 577 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:44:53 [scrapy.extensions.logstats] INFO: Crawled 626 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:45:53 [scrapy.extensions.logstats] INFO: Crawled 673 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:46:53 [scrapy.extensions.logstats] INFO: Crawled 723 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:47:53 [scrapy.extensions.logstats] INFO: Crawled 771 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:48:53 [scrapy.extensions.logstats] INFO: Crawled 819 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:49:53 [scrapy.extensions.logstats] INFO: Crawled 867 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:50:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,601236,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 15:50:53 [scrapy.extensions.logstats] INFO: Crawled 915 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:51:53 [scrapy.extensions.logstats] INFO: Crawled 965 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:52:53 [scrapy.extensions.logstats] INFO: Crawled 1014 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:53:53 [scrapy.extensions.logstats] INFO: Crawled 1063 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:54:53 [scrapy.extensions.logstats] INFO: Crawled 1111 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:55:53 [scrapy.extensions.logstats] INFO: Crawled 1159 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:56:53 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:57:53 [scrapy.extensions.logstats] INFO: Crawled 1258 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:58:53 [scrapy.extensions.logstats] INFO: Crawled 1307 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 15:59:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,603711,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 15:59:53 [scrapy.extensions.logstats] INFO: Crawled 1350 pages (at 43 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:00:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,603863,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:00:53 [scrapy.extensions.logstats] INFO: Crawled 1399 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:01:53 [scrapy.extensions.logstats] INFO: Crawled 1451 pages (at 52 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:02:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900911,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:02:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900913,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:02:53 [scrapy.extensions.logstats] INFO: Crawled 1486 pages (at 35 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:02:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900916,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:03:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900921,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:03:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900936,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:03:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900940,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:03:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900942,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:03:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900943,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:03:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://guba.eastmoney.com/list,900945,1,f_1.html> (referer: None)
Traceback (most recent call last):
  File "/Users/suool/anaconda3/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/suool/PycharmProjects/Guba/Guba/spiders/NewsSpider.py", line 42, in parse
    page_num = page_num.extract_first().split("|")[-3:]
AttributeError: 'NoneType' object has no attribute 'split'
2019-06-06 16:03:53 [scrapy.extensions.logstats] INFO: Crawled 1523 pages (at 37 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:04:53 [scrapy.extensions.logstats] INFO: Crawled 1523 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:05:53 [scrapy.extensions.logstats] INFO: Crawled 1523 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:06:53 [scrapy.extensions.logstats] INFO: Crawled 1523 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:07:53 [scrapy.extensions.logstats] INFO: Crawled 1523 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-06-06 16:07:58 [scrapy.crawler] INFO: Received SIGTERM, shutting down gracefully. Send again to force 
2019-06-06 16:07:58 [scrapy.core.engine] INFO: Closing spider (shutdown)
2019-06-06 16:07:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 476362,
 'downloader/request_count': 1530,
 'downloader/request_method_count/GET': 1530,
 'downloader/response_bytes': 26075897,
 'downloader/response_count': 1530,
 'downloader/response_status_count/200': 1522,
 'downloader/response_status_count/302': 7,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2019, 6, 6, 8, 7, 58, 317810),
 'log_count/ERROR': 13,
 'log_count/INFO': 45,
 'memusage/max': 98529280,
 'memusage/startup': 63684608,
 'response_received_count': 1523,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued/redis': 1529,
 'scheduler/enqueued/redis': 1529,
 'spider_exceptions/AttributeError': 13,
 'start_time': datetime.datetime(2019, 6, 6, 7, 31, 53, 937703)}
2019-06-06 16:07:58 [scrapy.core.engine] INFO: Spider closed (shutdown)
